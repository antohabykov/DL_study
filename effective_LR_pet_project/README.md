#ГИПОТЕЗА

В сверточных нейронных сетях при большом количестве эпох можно избежать кросс-валидации, так как можно оптимально изменять параметры в течение обучению с помощью, так называемой, эффективной скорости обучения.

#ЧТО БЫЛО СДЕЛАНО

Была произведена попытка повторить эксперимент [1] Samsung AI под руководством Дмитрия Ветрова в “домашних” условиях. Предполагалось детектировать схождения скорости обучения в течение 10000 эпох к одному "эффективному" значению. Для этого использовалась эффективная скорость обучения, которая пересчитывается каждую эпоху путем деления начальной скорости обучения на текущую норму весов модели. Таким образом, чем меньше сложность модели, тем выше скорость обучения, и наоборот. Этот подход описывал Twan van Laarhoven [2]. Для реализации эксперимента был выбран базовый датасет CIFAR10 и стандартная модель resnet18, аугментация не проводилась, использовалась L2-регуляризация. Обучение проводилось на 8 наборах гиперпараметров для эффективной скорости обучения и на 8 сочетаниях optimizers & schedulars, итого: 16 наборов гиперпараметров были обучены на 10000 эпох. 

В ходе эксперимента была получена практика в выдвижении гипотезы, дизайне эксперимента, обучении нейронных сетей на pytorch, а также визуализации и анализе данных с помощью matplotlib.

#ИНТЕРПРЕТАЦИЯ РЕЗУЛЬТАТОВ

Эксперимент показал, что значения эффективной скорости обучения не сходятся к одному оптимальному значению, более того, они слабо отклоняются от инициализированных значений. "Пилообразное" поведение детектировано было, как и в эксперименте [1], но только лишь при высоких значениях начальной скорости обучения и меньшем параметре L2-регуляризации. Таким образом, эксперимент показал, что способ оптимизации скорости обучения с помощью деления её на норму весов не обладает предполагавшимся преимуществом, отсутствием необходимости к кросс-валидации, так как зависит от начальной скорости обучения и значения L2-регуляризации. Можно предположить, что при другой модели или датасете, эффект все же может быть детектирован, но это предмет изучения для других экспериментов.

Однако стоит отметить, что точность на тестовой выборке была стабильно выше, чем при случайно выбранных сочетаниях optimizer & schedular & lr & reg. Это говорит, что при ограниченных ресурсах эффективная скорость обучения может быть полезна и её можно добавлять в набор параметров для валидации. Также в нескольких экспериментах был детектирован эффект, в ходе которого точность на тестовой выборке резко падает, а после падения возрастает. Этот же эффект был показан и в вебинаре [1], правда, практическую значимость в общем случае вывести не представляется возможным, и эта детекция лишь показывает необычную природу нейросетей.


#ССЫЛКИ

[1] Дмитрий Ветров, Вебинар "Необычные свойства функции потерь в глубинном обучении. Дмитрий Ветров, НИУ ВШЭ. 1 часть", ссылка: https://clck.ru/sTjkH
[2] Twan van Laarhoven, paper: "L2 Regularization versus Batch and Weight Normalization", ссылка: https://arxiv.org/abs/1706.05350